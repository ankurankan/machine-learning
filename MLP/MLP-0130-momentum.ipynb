{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "import scipy.io\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    '''\n",
    "    For load data and change shape to (x,y). x is the traing images and y is the label of the x.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, file):\n",
    "\n",
    "        self.data = scipy.io.loadmat(file, squeeze_me=True, struct_as_record=False)['mnist']\n",
    "        self.train_images = self.data.train_images\n",
    "        self.test_images = self.data.test_images\n",
    "        self.train_labels = self.data.train_labels\n",
    "        self.test_labels = self.data.test_labels\n",
    "\n",
    "        # transform the raw data to binary data\n",
    "        self.train_images = self.transform_images(self.train_images)\n",
    "        self.test_images = self.transform_images(self.test_images)\n",
    "\n",
    "        # reshape the training images to [784,1]\n",
    "        self.train_images = [np.reshape(x, (784, 1)) for x in self.train_images]\n",
    "        self.test_images = [np.reshape(x, (784, 1)) for x in self.test_images]\n",
    "\n",
    "        labels = np.asarray(self.train_labels)\n",
    "        selector = (labels == 3) | (labels == 7)\n",
    "        self.train_labels = self.train_labels[selector]\n",
    "        self.train_images = np.array(self.train_images)\n",
    "        self.train_images = self.train_images[selector]\n",
    "        ls= []\n",
    "        for i in self.train_labels:\n",
    "            if i == 3:\n",
    "                ls.append([[1.],[0.]])\n",
    "            else:\n",
    "                ls.append([[0.],[1.]])\n",
    "        self.train_labels = ls\n",
    "        \n",
    "        self.training_data = tuple(zip(self.train_images, self.train_labels))\n",
    "        \n",
    "#       test part\n",
    "        labels = np.asarray(self.test_labels)\n",
    "        selector = (labels == 3) | (labels == 7)\n",
    "        self.test_labels = self.test_labels[selector]\n",
    "        self.test_images = np.array(self.test_images)\n",
    "        self.test_images = self.test_images[selector]\n",
    "        ls= []\n",
    "        for i in self.test_labels:\n",
    "            if i == 3:\n",
    "                ls.append([[1.],[0.]])\n",
    "            else:\n",
    "                ls.append([[0.],[1.]])\n",
    "        self.test_labels = ls\n",
    "        \n",
    "        self.test_data = tuple(zip(self.test_images, self.test_labels))\n",
    "        \n",
    "        \n",
    "    # function to reshape\n",
    "    def transform_images(self, data):\n",
    "\n",
    "        reshaped = data.reshape(data.shape[0] * data.shape[1], data.shape[2])\n",
    "        swapped_axes = np.swapaxes(reshaped, 0, 1)\n",
    "        return swapped_axes * (1.0/256)\n",
    "#         return (swapped_axes > 122) * 2.0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = DataLoader('mnistALL.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, mu):\n",
    "        '''\n",
    "        sizes is the structure of the whole network shown by [first layer, second layer, ... , last year] as a list\n",
    "        different waies to initialize the weights and biases\n",
    "        '''\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.vb = [np.zeros(b.shape) for b in self.biases]\n",
    "        self.vw = [np.zeros(w.shape) for w in self.weights]\n",
    "        self.mu = mu\n",
    "        \n",
    "#better initialization of weights and biases \n",
    "#         self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "#         self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
    "#                         for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    # the feedward calculation of the network\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "    # stochastic gradient descent\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        error = []\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in xrange(epochs):\n",
    "#             random.shuffle(training_data)\n",
    "# not shuffle yet\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in xrange(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                error.append(self.evaluate(test_data)/(len(test_data) * 1.0))\n",
    "                print \"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test)\n",
    "                \n",
    "            else:\n",
    "                print \"Epoch {0} complete\".format(j)\n",
    "        return error\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            self.vb = [self.mu * vb - eta * db/len(mini_batch) \n",
    "                       for vb,db in zip(self.vb, delta_nabla_b)]\n",
    "            self.vw = [self.mu * vw - eta * dw/len(mini_batch) \n",
    "                       for vw,dw in zip(self.vw, delta_nabla_w)]\n",
    "            self.weights = [w + vw for w, vw in zip(self.weights, self.vw)]\n",
    "            self.biases = [b + vb for b, vb in zip(self.biases, self.vb)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        for l in xrange(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), np.argmax(y))\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations-y)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "Epoch 0: 1995 / 2038\n",
      "Epoch 1: 1993 / 2038\n",
      "Epoch 2: 1981 / 2038\n",
      "Epoch 3: 1983 / 2038\n",
      "Epoch 4: 1983 / 2038\n",
      "Epoch 5: 1987 / 2038\n",
      "Epoch 6: 1990 / 2038\n",
      "Epoch 7: 1985 / 2038\n",
      "Epoch 8: 1973 / 2038\n",
      "Epoch 9: 1953 / 2038\n",
      "Epoch 10: 1968 / 2038\n",
      "Epoch 11: 1955 / 2038\n",
      "Epoch 12: 1894 / 2038\n",
      "Epoch 13: 1958 / 2038\n",
      "Epoch 14: 1982 / 2038\n",
      "Epoch 15: 1981 / 2038\n",
      "Epoch 16: 1958 / 2038\n",
      "Epoch 17: 1903 / 2038\n",
      "Epoch 18: 1907 / 2038\n",
      "Epoch 19: 1976 / 2038\n",
      "Epoch 20: 1986 / 2038\n",
      "Epoch 21: 1985 / 2038\n",
      "Epoch 22: 1975 / 2038\n",
      "Epoch 23: 1973 / 2038\n",
      "Epoch 24: 1989 / 2038\n",
      "Epoch 25: 1971 / 2038\n",
      "Epoch 26: 1957 / 2038\n",
      "Epoch 27: 1951 / 2038\n",
      "Epoch 28: 1944 / 2038\n",
      "Epoch 29: 1937 / 2038\n",
      "Epoch 30: 1979 / 2038\n",
      "Epoch 31: 1979 / 2038\n",
      "Epoch 32: 1979 / 2038\n",
      "Epoch 33: 1979 / 2038\n",
      "Epoch 34: 1978 / 2038\n",
      "Epoch 35: 1978 / 2038\n",
      "Epoch 36: 1980 / 2038\n",
      "Epoch 37: 1980 / 2038\n",
      "Epoch 38: 1978 / 2038\n",
      "Epoch 39: 1976 / 2038\n",
      "Epoch 40: 1976 / 2038\n",
      "Epoch 41: 1977 / 2038\n",
      "Epoch 42: 1978 / 2038\n",
      "Epoch 43: 1978 / 2038\n",
      "Epoch 44: 1978 / 2038\n",
      "Epoch 45: 1980 / 2038\n",
      "Epoch 46: 1979 / 2038\n",
      "Epoch 47: 1980 / 2038\n",
      "Epoch 48: 1980 / 2038\n",
      "Epoch 49: 1979 / 2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:97: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "training_data = data.training_data\n",
    "validation_data = data.test_data\n",
    "\n",
    "\n",
    "print len(data.training_data[0][0])\n",
    "start_time = time.time()\n",
    "net = Network([784,50,2], 1)\n",
    "merror = net.SGD(training_data, 50, 10, 0.005, test_data=validation_data)\n",
    "mtime = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        '''\n",
    "        sizes is the structure of the whole network shown by [first layer, second layer, ... , last year] as a list\n",
    "        different waies to initialize the weights and biases\n",
    "        '''\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "# #better initialization of weights and biases \n",
    "#         self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "#         self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
    "#                         for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    # the feedward calculation of the network\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = tanh(np.dot(w, a)+b)\n",
    "        return a\n",
    "    # stochastic gradient descent\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        error = []\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in xrange(epochs):\n",
    "#             random.shuffle(training_data)\n",
    "# not shuffle yet\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in xrange(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                error.append(self.evaluate(test_data)/(len(test_data) * 1.0))\n",
    "                print \"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test)\n",
    "                \n",
    "            else:\n",
    "                print \"Epoch {0} complete\".format(j)\n",
    "        return error\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = tanh(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            tanh_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        for l in xrange(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = tanh_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), np.argmax(y))\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations-y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1983 / 2038\n",
      "Epoch 1: 1983 / 2038\n",
      "Epoch 2: 1978 / 2038\n",
      "Epoch 3: 1964 / 2038\n",
      "Epoch 4: 1972 / 2038\n",
      "Epoch 5: 1977 / 2038\n",
      "Epoch 6: 1974 / 2038\n",
      "Epoch 7: 1975 / 2038\n",
      "Epoch 8: 1980 / 2038\n",
      "Epoch 9: 1979 / 2038\n",
      "Epoch 10: 1980 / 2038\n",
      "Epoch 11: 1974 / 2038\n",
      "Epoch 12: 1976 / 2038\n",
      "Epoch 13: 1966 / 2038\n",
      "Epoch 14: 1970 / 2038\n",
      "Epoch 15: 1980 / 2038\n",
      "Epoch 16: 1995 / 2038\n",
      "Epoch 17: 1993 / 2038\n",
      "Epoch 18: 1984 / 2038\n",
      "Epoch 19: 1983 / 2038\n",
      "Epoch 20: 1973 / 2038\n",
      "Epoch 21: 1971 / 2038\n",
      "Epoch 22: 1965 / 2038\n",
      "Epoch 23: 1956 / 2038\n",
      "Epoch 24: 1923 / 2038\n",
      "Epoch 25: 1899 / 2038\n",
      "Epoch 26: 1852 / 2038\n",
      "Epoch 27: 1831 / 2038\n",
      "Epoch 28: 1817 / 2038\n",
      "Epoch 29: 1803 / 2038\n",
      "Epoch 30: 1875 / 2038\n",
      "Epoch 31: 1963 / 2038\n",
      "Epoch 32: 1967 / 2038\n",
      "Epoch 33: 1915 / 2038\n",
      "Epoch 34: 1928 / 2038\n",
      "Epoch 35: 1970 / 2038\n",
      "Epoch 36: 1961 / 2038\n",
      "Epoch 37: 1967 / 2038\n",
      "Epoch 38: 1909 / 2038\n",
      "Epoch 39: 1919 / 2038\n",
      "Epoch 40: 1971 / 2038\n",
      "Epoch 41: 1961 / 2038\n",
      "Epoch 42: 1963 / 2038\n",
      "Epoch 43: 1964 / 2038\n",
      "Epoch 44: 1965 / 2038\n",
      "Epoch 45: 1964 / 2038\n",
      "Epoch 46: 1963 / 2038\n",
      "Epoch 47: 1962 / 2038\n",
      "Epoch 48: 1968 / 2038\n",
      "Epoch 49: 1970 / 2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:97: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sgdnet = Network([784,50,2], 1)\n",
    "sgderror = sgdnet.SGD(training_data, 50, 10, 0.005, test_data=validation_data)\n",
    "sgdtime = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    s = str(100 * y)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'\n",
    "formatter = FuncFormatter(to_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEZCAYAAACjPJNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAcfMzKri/wO7RP33kpmVwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bfe5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoches = range(len(sgderror))\n",
    "plt.plot(epoches, merror,'b')\n",
    "plt.plot(epoches, sgderror,'r')\n",
    "\n",
    "\n",
    "plt.title('Plot of Stochastic Gradient Descent vs. Momentum')\n",
    "plt.xlabel('epoches')# make axis labels\n",
    "plt.ylabel('accuracies')\n",
    "\n",
    "plt.xlim(0.0, 50)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "plt.savefig(\"p401.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
