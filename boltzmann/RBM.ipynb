{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine\n",
    "\n",
    "<img src=\"files/RBM.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The energy function is defined as follows:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "E(\\textbf{v}, \\textbf{h}) = -\\sum\\limits_i a_i v_i - \\sum\\limits_j b_j h_j - \\sum\\limits_i \\sum\\limits_j v_i w_{ij} h_j\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Furthermore, the probability distributions are the following (with $\\sigma$ being the logistic sigmoid):\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(\\textbf{v}) &= \\frac{1}{Z} \\sum\\limits_{\\textbf{h}} e^{-E(\\textbf{v}, \\textbf{h})}\\\\\n",
    "P(h_j = \\mbox{on} | \\textbf{v}) &= \\sigma(b_j + \\sum\\limits_{i=1}^m v_i w_{ij})\\\\\n",
    "P(v_i = \\mbox{on} | \\textbf{h}) &= \\sigma(a_i + \\sum\\limits_{j=1}^n h_j w_{ij})\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "class RBM:\n",
    "    \"\"\"\n",
    "    Model for a Restricted Boltzmann Machine.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_visible, num_hidden, w=None, a=None, b=None):\n",
    "        \"\"\"\n",
    "        Initialize the Restricted Boltzmann Machine (RBM).\n",
    "        \n",
    "        :param num_visible: Number of visible cells.\n",
    "        :param num_hidden: Number of hidden cells.\n",
    "        :param w: Optional: initial weights between the visible units and the hidden units; (num_visible x num_hidden matrix).\n",
    "        :param a: Optional: initial bias for the visible units; (1 x num_visible) matrix.\n",
    "        :param b: Optional: initial bias for the hidden units; (1 x num_hidden) matrix.\n",
    "        \"\"\"\n",
    "        self.num_visible, self.num_hidden, self.w, self.a, self.b = num_visible, num_hidden, w, a, b\n",
    "        self.w = np.random.normal(0, 1, (num_visible, num_hidden)) if w is None else w\n",
    "        self.a = np.random.normal(0, 1, (1, num_visible)) if a is None else a\n",
    "        self.b = np.random.normal(0, 1, (1, num_hidden)) if b is None else b\n",
    "        \n",
    "    @staticmethod\n",
    "    def logistic_sigmoid(x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "    \n",
    "    def calculate_normalizing_constant_bruteforce(self):\n",
    "        Z = 0\n",
    "        for v in itertools.product([-1, 1], repeat=self.num_visible):\n",
    "            for h in itertools.product([-1, 1], repeat=self.num_hidden):\n",
    "                Z += np.exp(-self.calculate_energy(np.matrix(v), np.matrix(h)))\n",
    "        return Z\n",
    "    \n",
    "    def calculate_probability(self, v, normalizing_constant):\n",
    "        p = 0.\n",
    "        for h in itertools.product([-1, 1], repeat=self.num_hidden):\n",
    "            p += np.exp(-self.calculate_energy(v, np.matrix(h)))\n",
    "        return p / float(normalizing_constant)\n",
    "    \n",
    "    def calculate_energy(self, v, h):\n",
    "        \"\"\"\n",
    "        Calculates E(v, h).\n",
    "        \n",
    "        :param v: (1 x num_visible) matrix containing the state of the visible units.\n",
    "        :param h: (1 x num_hidden) matrix containing the state for the hidden units.\n",
    "        \"\"\"\n",
    "        return -np.dot(self.a, v.T) - np.dot(self.b, h.T) - np.dot(v, np.dot(self.w, h.T))\n",
    "    \n",
    "    def calculate_probabilities_h_given_v(self, v):\n",
    "        \"\"\"\n",
    "        Calculates p(h_j=1|v).\n",
    "        \n",
    "        :param v: (1 x num_visible) matrix containing the state of the visible units.\n",
    "        \"\"\"\n",
    "        return RBM.logistic_sigmoid(self.b + np.dot(v, self.w))\n",
    "    \n",
    "    def calculate_probabilities_v_given_h(self, h):\n",
    "        \"\"\"\n",
    "        Calculates p(v_i=1|h).\n",
    "        \n",
    "        :param h: (1 x num_hidden) matrix containing the state of the hidden units.\n",
    "        \"\"\"\n",
    "        return RBM.logistic_sigmoid(self.a + np.dot(h, self.w.T))\n",
    "    \n",
    "    def train(self, samples, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Train using the Contrastive Divergence (CD-1) procedure.\n",
    "        \n",
    "        :param samples: (num_samples x num_visible) matrix containing num_samples training samples.\n",
    "        :param learning_rate: The learning rate used in the CD-1 procedure.\n",
    "        \"\"\"\n",
    "        # Step 1: Take a training sample v, compute the probabilities of the hidden units and sample a hidden activation vector h from this probability distribution.\n",
    "        v = samples[np.random.randint(0, samples.shape[0]), :]\n",
    "        _, h = self.generate_sample(v, None, 1)\n",
    "        # Step 2: Compute the outer product of v and h and call this the positive gradient.\n",
    "        pos_gradient = np.outer(v, h)\n",
    "        # Step 3: From h, sample a reconstruction v' of the visible units, then resample the hidden activations h' from this. (Gibbs sampling step).\n",
    "        v2, _ = self.generate_sample(v, h, 2)\n",
    "        _, h2 = self.generate_sample(v2, h, 1)\n",
    "        # Step 4: Compute the outer product of v' and h' and call this the negative gradient.\n",
    "        neg_gradient = np.outer(v2, h2)\n",
    "        # Step 5: Now apply the updates.\n",
    "        dw = learning_rate * (pos_gradient - neg_gradient)\n",
    "        da = learning_rate * (v - v2)\n",
    "        db = learning_rate * (h - h2)\n",
    "        self.w += dw\n",
    "        self.a += da\n",
    "        self.b += db\n",
    "        return dw, da, db\n",
    "    \n",
    "    def generate_sample(self, v=None, h=None, num_rounds=200):\n",
    "        current_phase = 0 if v is not None else 1\n",
    "        v = v if v is not None else np.random.binomial(1, 0.5, (1, self.num_visible)) * 2 - 1\n",
    "        h = h if h is not None else np.random.binomial(1, 0.5, (1, self.num_hidden)) * 2 - 1\n",
    "        for _ in range(num_rounds):\n",
    "            if current_phase == 0:\n",
    "                p = self.calculate_probabilities_h_given_v(v)\n",
    "                h = np.random.binomial(1, p) * 2 - 1\n",
    "            else:\n",
    "                p = self.calculate_probabilities_v_given_h(h)\n",
    "                v = np.random.binomial(1, p) * 2 - 1\n",
    "            current_phase = (current_phase + 1) % 2\n",
    "        return v, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.0353503  -4.47074231]\n",
      " [ 5.78564685  4.04338838]]\n",
      "[[-0.43825892  0.04460119]]\n",
      "[[ 0.50491522  0.20497371]]\n"
     ]
    }
   ],
   "source": [
    "model = RBM(2, 2)\n",
    "for _ in range(10000):\n",
    "    model.train(np.matrix([[1, -1], [-1, 1]]), 0.1)\n",
    "    \n",
    "print(model.w)\n",
    "print(model.a)\n",
    "print(model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.80517118e-09]]\n",
      "[[ 0.91571475]]\n",
      "[[ 0.08428525]]\n",
      "[[  1.16966751e-09]]\n"
     ]
    }
   ],
   "source": [
    "Z = model.calculate_normalizing_constant_bruteforce()\n",
    "print(model.calculate_probability(np.matrix([-1, -1]), Z))\n",
    "print(model.calculate_probability(np.matrix([-1, 1]), Z))\n",
    "print(model.calculate_probability(np.matrix([1, -1]), Z))\n",
    "print(model.calculate_probability(np.matrix([1, 1]), Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -1]]:\t525\n",
      "[[-1, 1]]:\t468\n",
      "[[1, 1]]:\t5\n",
      "[[-1, -1]]:\t2\n"
     ]
    }
   ],
   "source": [
    "v_log = []\n",
    "for _ in range(1000):\n",
    "    v, _ = model.generate_sample()\n",
    "    v_log.append([v[0, 0], v[0, 1]])\n",
    "v_log = np.matrix(v_log)\n",
    "\n",
    "import operator\n",
    "counts = {}\n",
    "for r in range(v_log.shape[0]):\n",
    "    pattern = str(v_log[r, :].tolist())\n",
    "    if not pattern in counts:\n",
    "        counts[pattern] = 0\n",
    "    counts[pattern] += 1\n",
    "    \n",
    "for pattern, count in sorted(counts.items(), key=operator.itemgetter(1), reverse=True):\n",
    "    print(\"%s:\\t%d\" % (pattern, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.product at 0x7f829bb57ab0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
